import streamlit as st
import pandas as pd
import plotly.express as px
import datetime
import os
import requests
from dotenv import load_dotenv

# Page config
st.set_page_config(page_title="ì„œìš¸ ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ì‹¤ì‹œê°„ ë¶„ì„", layout="wide")

# Paths and Env
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# API Key Loading (Streamlit Cloud Secrets priority, then local .env)
# In Streamlit Cloud, set SEOUL_API_KEY in "Advanced settings -> Secrets"
if "SEOUL_API_KEY" in st.secrets:
    API_KEY = st.secrets["SEOUL_API_KEY"]
else:
    # Local fallback: try to find .env in various levels
    env_paths = [
        os.path.join(BASE_DIR, ".env"),
        os.path.join(BASE_DIR, "..", ".env"),
        os.path.join(BASE_DIR, "..", "..", ".env"),
        os.path.join(BASE_DIR, "..", "..", "..", ".env")
    ]
    for p in env_paths:
        if os.path.exists(p):
            load_dotenv(p)
            break
    API_KEY = os.getenv("SEOUL_API_KEY")

# Custom CSS for premium look
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stTabs [data-baseweb="tab-list"] { gap: 24px; }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        background-color: #ffffff;
        border-radius: 4px 4px 0px 0px;
        padding: 5px 20px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #f1f3f5;
        border-bottom: 2px solid #007bff;
        font-weight: bold;
    }
    .stMetric {
        background-color: white;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    </style>
    """, unsafe_allow_html=True)

@st.cache_data(ttl=3600)
def fetch_2026_api_data(api_key, max_pages=5):
    if not api_key:
        return pd.DataFrame()
    service_name = "tbLnOpendataRtmsV"
    all_rows = []
    
    # Only fetch 2026 data live
    for page in range(max_pages):
        start_idx = (page * 1000) + 1
        end_idx = start_idx + 999
        url = f"http://openapi.seoul.go.kr:8088/{api_key}/json/{service_name}/{start_idx}/{end_idx}/2026"
        try:
            response = requests.get(url)
            if response.status_code == 200:
                data = response.json()
                if service_name in data:
                    rows = data[service_name]['row']
                    all_rows.extend(rows)
                    if len(rows) < 1000: break
                else: break
            else: break
        except Exception: break
            
    return pd.DataFrame(all_rows)

@st.cache_data
def load_2025_csv():
    # Relative path search for deployment
    filename = "seoul_real_estate_2025_ë¶€ë™ì‚°ì‹¤ê±°ë˜ê°€.csv"
    possible_paths = [
        os.path.join(BASE_DIR, "data", filename),
        os.path.join(BASE_DIR, "..", "data", filename),
        os.path.join(BASE_DIR, "..", "..", "data", "korea", "data", filename),
        # Explicit long path as last resort (for your current local structure)
        r'c:\Users\ehdwn\Desktop\ì—…ë¡œë“œ í•„ìš”\OneDrive\Study\Fastcamp\ICB6\T_Choi\Procjet1\Real_Estate_Data_Analysis\data\korea\data\seoul_real_estate_2025_ë¶€ë™ì‚°ì‹¤ê±°ë˜ê°€.csv'
    ]
    
    for p in possible_paths:
        if os.path.exists(p):
            try:
                return pd.read_csv(p, encoding='utf-8')
            except:
                return pd.read_csv(p, encoding='cp949')
    
    st.error("2025ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return pd.DataFrame()

@st.cache_data
def load_local_data():
    # Try loading both years locally
    df25 = load_2025_csv()
    
    file_path_26 = os.path.join(BASE_DIR, "data", "seoul_real_estate_2026_ë¶€ë™ì‚°ì‹¤ê±°ë˜ê°€.csv")
    if not os.path.exists(file_path_26):
        file_path_26 = os.path.join(BASE_DIR, "data", "korea", "data", "seoul_real_estate_2026_ë¶€ë™ì‚°ì‹¤ê±°ë˜ê°€.csv")
        
    dfs = [df25]
    if os.path.exists(file_path_26):
        try:
            df26 = pd.read_csv(file_path_26, encoding='utf-8')
            dfs.append(df26)
        except:
            df26 = pd.read_csv(file_path_26, encoding='cp949')
            dfs.append(df26)
            
    return pd.concat(dfs, ignore_index=True)

def preprocess_data(df):
    if df.empty: return df
    df['CTRT_DAY'] = pd.to_datetime(df['CTRT_DAY'], format='%Y%m%d', errors='coerce')
    df = df.dropna(subset=['CTRT_DAY'])
    df = df[df['CTRT_DAY'] >= '2025-01-01']
    df['THING_AMT'] = pd.to_numeric(df['THING_AMT'], errors='coerce')
    df['THING_AMT'] = df['THING_AMT'] / 10000.0
    return df

# Sidebar for Setup
st.sidebar.title("ğŸ› ï¸ ë°ì´í„° ì˜µì…˜")
option = st.sidebar.radio("ë°ì´í„° ëª¨ë“œ", ["ë¡œì»¬ (25'CSV) + ì‹¤ì‹œê°„ (26'API)", "ì „ì²´ ë¡œì»¬ ëª¨ë“œ"])

refresh = st.sidebar.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨")
if refresh:
    st.cache_data.clear()

if option == "ë¡œì»¬ (25'CSV) + ì‹¤ì‹œê°„ (26'API)":
    with st.spinner("2025ë…„ ë°ì´í„° ë¡œë“œ ì¤‘..."):
        df25 = load_2025_csv()
    
    if API_KEY:
        with st.spinner("2026ë…„ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            df26 = fetch_2026_api_data(API_KEY)
            df_raw = pd.concat([df25, df26], ignore_index=True)
            st.sidebar.success(f"2026ë…„ ë°ì´í„° {len(df26)}ê±´ ì¶”ê°€ë¨")
    else:
        st.sidebar.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. 2025ë…„ ë°ì´í„°ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
        df_raw = df25
else:
    with st.spinner("ë¡œì»¬ íŒŒì¼ ë¡œë“œ ì¤‘..."):
        df_raw = load_local_data()

df = preprocess_data(df_raw)

# UI Starts
st.title("ğŸ™ï¸ ì„œìš¸ ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
if not df.empty:
    st.info(f"ë°ì´í„° ê¸°ì¤€ì¼: {df['CTRT_DAY'].max().strftime('%Y-%m-%d')} | ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

tab1, tab2 = st.tabs(["ğŸ“Š 10ëŒ€ ëŒ€ë‹¨ì§€ í˜„í™©", "ğŸ  íƒœê°•ì•„íŒŒíŠ¸ (ê³µë¦‰ë™)"])

# Defined Top 10 Mega Complexes
mega_complexes_keywords = [
    'í—¬ë¦¬ì˜¤ì‹œí‹°', 'íŒŒí¬ë¦¬ì˜¤', 'ì ì‹¤ì—˜ìŠ¤', 'ë¦¬ì„¼ì¸ ', 'ê³ ë•ê·¸ë¼ì‹œì›€', 
    'ê³ ë•ì•„ë¥´í…Œì˜¨', 'ì˜¬ë¦¼í”½ì„ ìˆ˜ê¸°ìì´Œ', 'ì„¼íŠ¸ë¼ìŠ¤', 'ë§ˆí¬ë˜ë¯¸ì•ˆí‘¸ë¥´ì§€ì˜¤', 'ì˜¬ë¦¼í”½íŒŒí¬í¬ë ˆì˜¨'
]

def get_filtered_mega_data(df, keywords):
    pattern = '|'.join(keywords)
    m_df = df[df['BLDG_NM'].str.contains(pattern, na=False)].copy()
    
    def get_group_name(name):
        for k in keywords:
            if k in name: return k
        return name
    
    m_df['GROUP_NM'] = m_df['BLDG_NM'].apply(get_group_name)
    m_df['AREA_ROUND'] = m_df['ARCH_AREA'].round(0)
    
    # Filter each group by its most frequent area (Mode)
    final_dfs = []
    for g_name in m_df['GROUP_NM'].unique():
        group = m_df[m_df['GROUP_NM'] == g_name]
        main_area = group['AREA_ROUND'].mode()[0]
        # Keep only records matching the main area (within +/- 2 range for safety)
        group_filtered = group[group['AREA_ROUND'] == main_area].copy()
        group_filtered['MAIN_AREA'] = main_area
        final_dfs.append(group_filtered)
    
    return pd.concat(final_dfs, ignore_index=True) if final_dfs else pd.DataFrame()

mega_filtered = get_filtered_mega_data(df, mega_complexes_keywords)

with tab1:
    st.header("ì„œìš¸ 10ëŒ€ ëŒ€ë‹¨ì§€ ì£¼ë ¥ í‰í˜• ë¶„ì„")
    st.caption("â€» ê° ë‹¨ì§€ë³„ë¡œ ê°€ì¥ ê±°ë˜ê°€ ë§ì€ ëŒ€í‘œ í‰í˜•(Area) ë°ì´í„°ë§Œì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.")
    
    if mega_filtered.empty:
        st.warning("ë¶„ì„í•  ë‹¨ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ“… ì£¼ë ¥ í‰í˜•ë³„ ìµœì‹  ì‹¤ê±°ë˜")
            display_cols = ['CTRT_DAY', 'GROUP_NM', 'MAIN_AREA', 'THING_AMT', 'FLR']
            recent_mega = mega_filtered.sort_values('CTRT_DAY', ascending=False).head(50)
            st.dataframe(recent_mega[display_cols].rename(columns={
                'CTRT_DAY': 'ê³„ì•½ì¼', 'GROUP_NM': 'ë‹¨ì§€ëª…', 'MAIN_AREA': 'í‰í˜•(ã¡)',
                'THING_AMT': 'ê±°ë˜ê¸ˆì•¡(ì–µ)', 'FLR': 'ì¸µ'
            }), use_container_width=True, height=450)

        with col2:
            st.subheader("ğŸ“ˆ ì£¼ë ¥ í‰í˜• í‰ê·  ê°€ê²© ì¶”ì´")
            mega_filtered['YEAR_MONTH'] = mega_filtered['CTRT_DAY'].dt.to_period('M').astype(str)
            m_trend = mega_filtered.groupby(['YEAR_MONTH', 'GROUP_NM'])['THING_AMT'].mean().reset_index()
            
            fig = px.line(m_trend, x='YEAR_MONTH', y='THING_AMT', color='GROUP_NM',
                         labels={'THING_AMT': 'í‰ê·  ê±°ë˜ê¸ˆì•¡(ì–µ)', 'YEAR_MONTH': 'ê³„ì•½ë…„ì›”'},
                         title="ë‹¨ì§€ë³„ ëŒ€í‘œ í‰í˜• ê°€ê²© ë³€ë™", markers=True)
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("---")
        st.subheader("ğŸ¢ ë‹¨ì§€ë³„ ëŒ€í‘œ í‰í˜• ìš”ì•½")
        m_stats = mega_filtered.groupby(['GROUP_NM', 'MAIN_AREA']).agg({
            'THING_AMT': ['count', 'mean', 'max', 'min']
        }).reset_index()
        m_stats.columns = ['ë‹¨ì§€ëª…', 'ëŒ€í‘œí‰í˜•(ã¡)', 'ê±°ë˜ê±´ìˆ˜', 'í‰ê· ê°€(ì–µ)', 'ìµœê³ ê°€(ì–µ)', 'ìµœì†Œê°€(ì–µ)']
        st.table(m_stats.style.format({
            'í‰ê· ê°€(ì–µ)': '{:.2f}', 'ìµœê³ ê°€(ì–µ)': '{:.2f}', 'ìµœì†Œê°€(ì–µ)': '{:.2f}'
        }))

with tab2:
    st.header("ë…¸ì›êµ¬ ê³µë¦‰ë™ íƒœê°•ì•„íŒŒíŠ¸ ìƒì„¸ë¶„ì„")
    
    # Area filter UI
    area_choice = st.radio("ğŸ  í‰í˜• ì„ íƒ", ["49ã¡ íƒ€ì…", "59ã¡ íƒ€ì…"], horizontal=True)
    # 49.6 rounds to 50, so let's use range or specific rounding that matches user expectation
    # Most people call 49.60 as "49 type" or "21 pyuong". 
    # Let's use int() or floor() so 49.6 -> 49
    target_area = 49 if "49" in area_choice else 59
    
    taegang_df = df[df['BLDG_NM'].str.contains('íƒœê°•', na=False)].copy()
    # Use floor to capture 49.x as 49
    taegang_df['AREA_INT'] = taegang_df['ARCH_AREA'].astype(int)
    taegang_filtered = taegang_df[taegang_df['AREA_INT'] == target_area].copy()
    
    if taegang_filtered.empty:
        st.warning(f"{target_area}ã¡ íƒ€ì…ì˜ ê±°ë˜ ë‚´ì—­ì´ ì„ íƒëœ ë°ì´í„° ë²”ìœ„ ë‚´ì— ì—†ìŠµë‹ˆë‹¤.")
        # Fallback check: maybe it rounds higher?
        alt_area = 50 if target_area == 49 else 60
        alt_filtered = taegang_df[taegang_df['AREA_INT'] == alt_area].copy()
        if not alt_filtered.empty:
            st.info(f"ì°¸ê³ : {target_area}ã¡ ëŒ€ì‹  {alt_area}ã¡(ì‹¤ì œ {alt_filtered['ARCH_AREA'].iloc[0]}ã¡) ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
            taegang_filtered = alt_filtered
            target_area = alt_area

    if not taegang_filtered.empty:
        st.info(f"ğŸ“ íƒœê°•ì•„íŒŒíŠ¸ {target_area}ã¡ íƒ€ì… ë¶„ì„ ê²°ê³¼")
        colA, colB = st.columns([1, 1])
        with colA:
            st.subheader("ğŸ“… ì‹¤ê±°ë˜ ë‚´ì—­")
            t_display = taegang_filtered.sort_values('CTRT_DAY', ascending=False)
            st.dataframe(t_display[['CTRT_DAY', 'THING_AMT', 'ARCH_AREA', 'FLR']].rename(columns={
                'CTRT_DAY': 'ê³„ì•½ì¼', 'THING_AMT': 'ê±°ë˜ê¸ˆì•¡(ì–µ)', 'ARCH_AREA': 'ì „ìš©ë©´ì (ã¡)', 'FLR': 'ì¸µ'
            }), use_container_width=True, height=450)
            
        with colB:
            st.subheader("ğŸ“ˆ ê±°ë˜ê°€ê²© ì¶”ì„¸")
            taegang_filtered['YEAR_MONTH'] = taegang_filtered['CTRT_DAY'].dt.to_period('M').astype(str)
            t_monthly = taegang_filtered.groupby('YEAR_MONTH')['THING_AMT'].mean().reset_index()
            t_monthly = t_monthly.sort_values('YEAR_MONTH')
            
            # Main Line Chart
            fig_t = px.line(t_monthly, x='YEAR_MONTH', y='THING_AMT', 
                          title=f"íƒœê°• {target_area}ã¡ ì›”ë³„ í‰ê· ê°€ ì¶”ì´",
                          markers=True,
                          color_discrete_sequence=['#4A90E2'])
            
            # Add Trendline (Simple Linear Regression)
            if len(t_monthly) > 1:
                import numpy as np
                x = np.arange(len(t_monthly))
                y = t_monthly['THING_AMT'].values
                z = np.polyfit(x, y, 1)
                p = np.poly1d(z)
                
                fig_t.add_scatter(x=t_monthly['YEAR_MONTH'], y=p(x), 
                                 mode='lines', 
                                 name='ê°€ê²© ì¶”ì„¸ì„ ',
                                 line=dict(color='red', width=2, dash='dot'))
                
            st.plotly_chart(fig_t, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ” ì¸µë³„ ê±°ë˜ ë¶„í¬ (ì‚°ì ë„)")
        fig_scat = px.scatter(taegang_filtered, x='CTRT_DAY', y='THING_AMT', color='FLR',
                               labels={'CTRT_DAY': 'ê³„ì•½ì¼', 'THING_AMT': 'ê±°ë˜ê¸ˆì•¡(ì–µ)', 'FLR': 'ì¸µ'},
                               hover_data=['ARCH_AREA'],
                               title=f"{target_area}ã¡ ê±°ë˜ ìƒì„¸ ë¶„í¬")
        st.plotly_chart(fig_scat, use_container_width=True)

st.sidebar.markdown("---")
st.sidebar.info("""
**ì‹¤ì‹œê°„ API ëª¨ë“œ ì•ˆë‚´**:
- ìµœê·¼ 2,000ê±´ì˜ ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
- 2025ë…„ ìµœì‹  ì‹¤ê±°ë˜ê°€ë¥¼ ì¦‰ì‹œ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë°ì´í„° ë¡œë”©ì´ ëŠë¦´ ê²½ìš° 'ë¡œì»¬ CSV' ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
""")

# Note: THING_AMT in raw data is often in 10,000 KRW.
# If original data is 56000, then it's 5.6 Eok.
# The division by 10000.0 is used to show it in Eok.
